{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS203-Assignment-7-Q2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6tzwuyFvR6K",
        "outputId": "53da47e9-9738-4a3e-b707-05ae64035f21",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf104e28-f4d5-4018-9161-95fbf1538dff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cf104e28-f4d5-4018-9161-95fbf1538dff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving haberman.csv to haberman.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp-qaj1WVsRX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZVgy4nzj1p9"
      },
      "source": [
        "# Loading The Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEvvQYXDVuLR",
        "outputId": "fe3d98d1-ab56-4b04-e7f3-43d47aa32995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Reading the data\n",
        "df = pd.read_csv('haberman.csv')\n",
        "display(df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "      <td>62</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>59</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31</td>\n",
              "      <td>65</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>75</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>76</td>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>77</td>\n",
              "      <td>65</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>78</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>83</td>\n",
              "      <td>58</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>306 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     X1  X2  X3  Y\n",
              "0    30  64   1  1\n",
              "1    30  62   3  1\n",
              "2    30  65   0  1\n",
              "3    31  59   2  1\n",
              "4    31  65   4  1\n",
              "..   ..  ..  .. ..\n",
              "301  75  62   1  1\n",
              "302  76  67   0  1\n",
              "303  77  65   3  1\n",
              "304  78  65   1  2\n",
              "305  83  58   2  2\n",
              "\n",
              "[306 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZc-IR0Lj5EV"
      },
      "source": [
        "# EDA Of The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K71oqvPJVx-_",
        "outputId": "d146fe17-4c85-4d32-f801-0426aacdd2ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for col in df.columns.values:\n",
        "    \n",
        "    # Getting list of unique values in each column\n",
        "    unique_list = pd.unique(df[col])\n",
        "\n",
        "    print(\"Datatype of {} is: \".format(col), df[col].dtype)\n",
        "    print(\"Number of unique values for {} are: \".format(col), len(unique_list))\n",
        "\n",
        "    # Converting a column to a boolean array checking for null values\n",
        "    is_null = pd.isnull(df[col])\n",
        "\n",
        "    # Calculating total null values\n",
        "    total_null = np.sum(is_null)\n",
        "\n",
        "    print(\"Number of missing entries for {} are: \".format(col), total_null)\n",
        "    print(\"Number of non-missing entries for {} are: \".format(col), df[col].shape[0] - total_null)\n",
        "\n",
        "    print(\"---------------\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datatype of X1 is:  int64\n",
            "Number of unique values for X1 are:  49\n",
            "Number of missing entries for X1 are:  0\n",
            "Number of non-missing entries for X1 are:  306\n",
            "---------------\n",
            "Datatype of X2 is:  int64\n",
            "Number of unique values for X2 are:  12\n",
            "Number of missing entries for X2 are:  0\n",
            "Number of non-missing entries for X2 are:  306\n",
            "---------------\n",
            "Datatype of X3 is:  int64\n",
            "Number of unique values for X3 are:  31\n",
            "Number of missing entries for X3 are:  0\n",
            "Number of non-missing entries for X3 are:  306\n",
            "---------------\n",
            "Datatype of Y is:  int64\n",
            "Number of unique values for Y are:  2\n",
            "Number of missing entries for Y are:  0\n",
            "Number of non-missing entries for Y are:  306\n",
            "---------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7IG9wN_j8FQ"
      },
      "source": [
        "# Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1g9pMGQVytk",
        "outputId": "a0196d9b-c282-45dc-e0a8-32e7f5a6e6d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "plt.figure(figsize = (15, 7))\n",
        "\n",
        "# Calculating correlation between all columns\n",
        "var_corr = df.corr()\n",
        "\n",
        "# Plotting correlation heatmap\n",
        "sns.heatmap(var_corr, xticklabels = var_corr.columns, yticklabels = var_corr.columns, annot = True, vmin=-1, vmax=1, center= 0) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1600568048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtEcjMJsj-3M"
      },
      "source": [
        "# Preparing The Data (Pre-Processing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4AamF0gXRNA",
        "outputId": "eb1db1b6-3a0f-4e2c-802d-320ac5ce987c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Extracting the label column\n",
        "Y = df['Y']\n",
        "\n",
        "# Dropping the label column from the main dataset\n",
        "df = df.drop('Y', axis = 1)\n",
        "display(df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "      <td>62</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>59</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31</td>\n",
              "      <td>65</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>75</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>76</td>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>77</td>\n",
              "      <td>65</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>78</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>83</td>\n",
              "      <td>58</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>306 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     X1  X2  X3\n",
              "0    30  64   1\n",
              "1    30  62   3\n",
              "2    30  65   0\n",
              "3    31  59   2\n",
              "4    31  65   4\n",
              "..   ..  ..  ..\n",
              "301  75  62   1\n",
              "302  76  67   0\n",
              "303  77  65   3\n",
              "304  78  65   1\n",
              "305  83  58   2\n",
              "\n",
              "[306 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CElDNnmnXX0W",
        "outputId": "20773de7-cb1c-4217-b84c-3e4f3439f921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Converting the data into numpy arrays\n",
        "X = np.array(df)\n",
        "Y = np.array(Y)\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(306, 3)\n",
            "(306,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCk45SPFkHeV"
      },
      "source": [
        "# Train-Test Split Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyh1vBUkXdLC"
      },
      "source": [
        "# Splitting the data into train and test sets\n",
        "def data_split(test_split = 0.2):\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = test_split, shuffle = True)\n",
        "    return X_train, X_test, Y_train, Y_test"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9t1AFRFkMf8"
      },
      "source": [
        "# Logistic Regression Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DcX9sOLXg1s"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "'''\n",
        "A function to carry out logistic regression\n",
        "\n",
        "Here, C is a parameter which specifies the inverse of the regularization strength, in a sense\n",
        "So, smaller values of C lead to stronger regularization\n",
        "'''\n",
        "\n",
        "def logistic_regression(X, Y, reg_inverse = 1.0, penalty = 'l2'):\n",
        "\n",
        "    clf = LogisticRegression(penalty = penalty, C = reg_inverse).fit(X, Y)\n",
        "    return clf"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5q0vIkikSi7"
      },
      "source": [
        "# Classification Error Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-r9gycneX5C"
      },
      "source": [
        "def classification_error(Y_pred, Y_actual):\n",
        "\n",
        "    # Total test values\n",
        "    total_entries = len(Y_pred)\n",
        "    \n",
        "    # Number of values wrongly predicted by the model\n",
        "    wrong_values = 0\n",
        "    \n",
        "    for i in range(total_entries):\n",
        "\n",
        "        if Y_pred[i] != Y_actual[i]:\n",
        "            wrong_values += 1\n",
        "\n",
        "    error = float(wrong_values)/float(total_entries)\n",
        "    return error"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmJ4T2DHkZuW"
      },
      "source": [
        "# Logistic Regression With Varying Train-Test Splits And Regularization Strength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX_5QM7GaCLh",
        "outputId": "8259d2a7-02c6-49bf-eb7b-859f04f02fc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Possible train-test splits\n",
        "test_splits = [0.1, 0.2, 0.3, 0.4]\n",
        "\n",
        "# Possible values of the inverse of the regularization strength\n",
        "reg_inverse_values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
        "\n",
        "for test_split in test_splits:\n",
        "\n",
        "    for reg_inverse_value in reg_inverse_values:\n",
        "\n",
        "        print(f\"Test Split Value: {test_split}\")\n",
        "        print(f\"Regularization Strength: {1/reg_inverse_value}\")\n",
        "        \n",
        "        X_train, X_test, Y_train, Y_test = data_split(test_split = test_split)\n",
        "        \n",
        "        # Normalizing the different features in the data\n",
        "        X_train = preprocessing.scale(X_train)\n",
        "        X_test = preprocessing.scale(X_test)\n",
        "        \n",
        "        # Fitting the data to the logistic regression model\n",
        "        clf = logistic_regression(X_train, Y_train)\n",
        "        \n",
        "        # Extract the coefficients of the trained logistic model\n",
        "        coef = clf.coef_\n",
        "\n",
        "        # Extract the intercept of the trained logistic model\n",
        "        intercept = clf.intercept_\n",
        "\n",
        "        print(f\"Coefficients of the trained logistic model are: {coef}\")\n",
        "        print(f\"Intercept of the trained logistic model is: {intercept}\")\n",
        "\n",
        "        # Carrying out predictions on the test data\n",
        "        Y_pred = clf.predict(X_test)\n",
        "        print(f\"The predicted survival status of the patients in the test dataset sre: {Y_pred}\")\n",
        "\n",
        "        # Computing the error in the predicted values\n",
        "        error = classification_error(Y_pred, Y_test)\n",
        "        print(f\"The classification error in the test data prediction is: {error} \\n\")\n",
        "\n",
        "        print(\"----------\\n\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Split Value: 0.1\n",
            "Regularization Strength: 100.0\n",
            "Coefficients of the trained logistic model are: [[0.11187292 0.08419266 0.71059805]]\n",
            "Intercept of the trained logistic model is: [-1.10316544]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1]\n",
            "The classification error in the test data prediction is: 0.2903225806451613 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 33.333333333333336\n",
            "Coefficients of the trained logistic model are: [[ 0.23438938 -0.00409387  0.5564721 ]]\n",
            "Intercept of the trained logistic model is: [-1.10451574]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.3225806451612903 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 10.0\n",
            "Coefficients of the trained logistic model are: [[ 0.21449959 -0.07620136  0.7280304 ]]\n",
            "Intercept of the trained logistic model is: [-1.01407843]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.1935483870967742 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 3.3333333333333335\n",
            "Coefficients of the trained logistic model are: [[ 0.14980152 -0.05937622  0.64709766]]\n",
            "Intercept of the trained logistic model is: [-1.10671019]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.25806451612903225 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 1.0\n",
            "Coefficients of the trained logistic model are: [[ 0.22164779 -0.02337203  0.60471245]]\n",
            "Intercept of the trained logistic model is: [-1.0714687]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.1935483870967742 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 0.3333333333333333\n",
            "Coefficients of the trained logistic model are: [[ 0.20488122 -0.01050803  0.59028883]]\n",
            "Intercept of the trained logistic model is: [-1.04826331]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.16129032258064516 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 0.1\n",
            "Coefficients of the trained logistic model are: [[ 0.25044025 -0.01718675  0.60456009]]\n",
            "Intercept of the trained logistic model is: [-1.11510253]\n",
            "The predicted survival status of the patients in the test dataset sre: [2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.3225806451612903 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.1\n",
            "Regularization Strength: 0.03333333333333333\n",
            "Coefficients of the trained logistic model are: [[0.18992474 0.00076555 0.58996784]]\n",
            "Intercept of the trained logistic model is: [-1.10758379]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.3225806451612903 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 100.0\n",
            "Coefficients of the trained logistic model are: [[ 0.28994487 -0.057804    0.63872723]]\n",
            "Intercept of the trained logistic model is: [-1.12390708]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
            " 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2903225806451613 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 33.333333333333336\n",
            "Coefficients of the trained logistic model are: [[ 0.21614694 -0.13430949  0.61141644]]\n",
            "Intercept of the trained logistic model is: [-0.95585559]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1]\n",
            "The classification error in the test data prediction is: 0.1774193548387097 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 10.0\n",
            "Coefficients of the trained logistic model are: [[ 0.22445974 -0.0470973   0.51219368]]\n",
            "Intercept of the trained logistic model is: [-1.17557612]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2903225806451613 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 3.3333333333333335\n",
            "Coefficients of the trained logistic model are: [[ 0.25136593 -0.0928204   0.50910051]]\n",
            "Intercept of the trained logistic model is: [-1.01937524]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.20967741935483872 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 1.0\n",
            "Coefficients of the trained logistic model are: [[0.25350175 0.0158121  0.55792842]]\n",
            "Intercept of the trained logistic model is: [-1.09018972]\n",
            "The predicted survival status of the patients in the test dataset sre: [2 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.27419354838709675 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 0.3333333333333333\n",
            "Coefficients of the trained logistic model are: [[ 0.25246135 -0.03315275  0.89753826]]\n",
            "Intercept of the trained logistic model is: [-1.16698768]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.3064516129032258 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 0.1\n",
            "Coefficients of the trained logistic model are: [[ 0.29059386 -0.10063004  0.83335666]]\n",
            "Intercept of the trained logistic model is: [-1.14786682]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.3387096774193548 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.2\n",
            "Regularization Strength: 0.03333333333333333\n",
            "Coefficients of the trained logistic model are: [[ 0.24979383 -0.00552772  0.64646384]]\n",
            "Intercept of the trained logistic model is: [-1.20197974]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.3225806451612903 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 100.0\n",
            "Coefficients of the trained logistic model are: [[0.16655624 0.11395569 0.53898119]]\n",
            "Intercept of the trained logistic model is: [-1.08567127]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.25 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 33.333333333333336\n",
            "Coefficients of the trained logistic model are: [[ 0.17069742 -0.07403546  0.55296779]]\n",
            "Intercept of the trained logistic model is: [-1.1330808]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1\n",
            " 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2717391304347826 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 10.0\n",
            "Coefficients of the trained logistic model are: [[ 0.19071336 -0.00474813  0.58978816]]\n",
            "Intercept of the trained logistic model is: [-0.96369174]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1\n",
            " 2 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.20652173913043478 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 3.3333333333333335\n",
            "Coefficients of the trained logistic model are: [[ 0.30914787 -0.09804973  0.87077887]]\n",
            "Intercept of the trained logistic model is: [-1.01015316]\n",
            "The predicted survival status of the patients in the test dataset sre: [2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
            " 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2]\n",
            "The classification error in the test data prediction is: 0.25 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 1.0\n",
            "Coefficients of the trained logistic model are: [[0.36830861 0.01129919 0.42187573]]\n",
            "Intercept of the trained logistic model is: [-1.27664364]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.32608695652173914 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 0.3333333333333333\n",
            "Coefficients of the trained logistic model are: [[ 0.31660027 -0.1501184   0.59271264]]\n",
            "Intercept of the trained logistic model is: [-1.21274476]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.31521739130434784 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 0.1\n",
            "Coefficients of the trained logistic model are: [[ 0.27792669 -0.23633751  0.65296051]]\n",
            "Intercept of the trained logistic model is: [-1.0849018]\n",
            "The predicted survival status of the patients in the test dataset sre: [2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
            " 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2608695652173913 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.3\n",
            "Regularization Strength: 0.03333333333333333\n",
            "Coefficients of the trained logistic model are: [[0.16135801 0.00204151 0.61406529]]\n",
            "Intercept of the trained logistic model is: [-1.01939177]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 2 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2391304347826087 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 100.0\n",
            "Coefficients of the trained logistic model are: [[0.38470609 0.23726293 1.07208888]]\n",
            "Intercept of the trained logistic model is: [-0.91850048]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
            " 1 1 1 1 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1\n",
            " 1 1 2 1 1 1 1 1 1 2 1 1 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1\n",
            " 1 1 2 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.24390243902439024 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 33.333333333333336\n",
            "Coefficients of the trained logistic model are: [[ 0.258139   -0.19249847  0.62240196]]\n",
            "Intercept of the trained logistic model is: [-0.97228521]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1\n",
            " 1 1 1 1 1 2 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.21951219512195122 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 10.0\n",
            "Coefficients of the trained logistic model are: [[0.23885209 0.10751951 0.69166328]]\n",
            "Intercept of the trained logistic model is: [-0.98331917]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1\n",
            " 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 2 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.21138211382113822 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 3.3333333333333335\n",
            "Coefficients of the trained logistic model are: [[ 0.11329059 -0.03383233  0.50579293]]\n",
            "Intercept of the trained logistic model is: [-1.12699669]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 2 1 1 1 1 1 2 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2764227642276423 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 1.0\n",
            "Coefficients of the trained logistic model are: [[ 0.17888977 -0.07286999  0.68149662]]\n",
            "Intercept of the trained logistic model is: [-1.10496723]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
            " 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2764227642276423 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 0.3333333333333333\n",
            "Coefficients of the trained logistic model are: [[0.15212805 0.04956448 0.62398601]]\n",
            "Intercept of the trained logistic model is: [-1.1117979]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.2764227642276423 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 0.1\n",
            "Coefficients of the trained logistic model are: [[0.28698741 0.08189882 0.65630502]]\n",
            "Intercept of the trained logistic model is: [-1.0406894]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1\n",
            " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "The classification error in the test data prediction is: 0.23577235772357724 \n",
            "\n",
            "----------\n",
            "\n",
            "Test Split Value: 0.4\n",
            "Regularization Strength: 0.03333333333333333\n",
            "Coefficients of the trained logistic model are: [[ 0.22387943 -0.03846412  0.51032275]]\n",
            "Intercept of the trained logistic model is: [-1.17234946]\n",
            "The predicted survival status of the patients in the test dataset sre: [1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1\n",
            " 1 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2]\n",
            "The classification error in the test data prediction is: 0.2682926829268293 \n",
            "\n",
            "----------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYtw6bq4i3Va"
      },
      "source": [
        "# Result:\n",
        "\n",
        "The best model obtained out of the tried combinations of the train-test splits and the regularization strength is the one with a train and test split of 90:10 and regularization strength of 0.33 with a classification error of 0.16 (or 84% accuracy approximately) on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb62qg8IgpWJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}